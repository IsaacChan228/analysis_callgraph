# Multi-Tool Call Graph Comparison Framework

## Overview
This framework provides automated comparison and analysis of call graphs generated by multiple binary analysis tools. It standardizes function names across different tools, performs comprehensive statistical analysis, and generates visualizations to compare the effectiveness and characteristics of each analysis tool.

## Supported Analysis Tools
The framework currently supports comparison of four major binary analysis tools:
- **Radare2** - Open-source static analysis framework
- **Angr Fast** - Angr symbolic execution engine (fast analysis mode)
- **Angr Emul** - Angr symbolic execution engine (emulation mode)  
- **Ghidra** - NSA's open-source software reverse engineering framework

## Analysis Methodology

### Input Format Support
- **DOT format** (.dot) - Standard graph description language used by Radare2 and Angr
- **Ghidra GF format** (.gf) - Ghidra's native graph format
- Automatic format detection and parsing based on file extension and content structure

### Function Name Standardization
The framework implements comprehensive function name normalization to enable meaningful comparison across tools:
- Removes tool-specific prefixes (`dbg.`, `sym.`, `imp.`, `fcn.`, `reloc.`, `unk.`)
- Strips address suffixes and labels (`.0x[address]`, `@0x[address]`, `_0x[address]`)
- Handles compiler-generated suffixes (`.part.N`, `.isra.N`, `.cold.N`)
- Filters out pure addresses, switch cases, and invalid function names
- Normalizes leading underscores and duplicate definitions

### Graph Analysis and Metrics
The framework performs comprehensive graph-theoretic analysis using NetworkX:
- **Node Analysis**: Function count, unique function identification
- **Edge Analysis**: Call relationship mapping and validation
- **Graph Density**: Measures connectivity (edges / possible_edges)
- **Degree Analysis**: In-degree and out-degree statistics
- **Connected Components**: Strongly connected component identification
- **Jaccard Similarity**: Pairwise tool comparison using intersection/union ratios

### Function Classification System
Functions are automatically classified into two categories using pattern matching:
- **High-Level Functions**: Entry points, main functions, library calls, user-defined functions
- **Low-Level Functions**: Address-based labels, compiler-generated symbols, PLT/GOT entries

Classification patterns include:
```python
high_level_patterns = [
    r'^main$', r'^_start$', r'^entry$',
    r'.*init.*', r'.*setup.*', r'.*process.*',
    r'.*handle.*', r'.*parse.*', r'.*print.*'
]

low_level_patterns = [
    r'^0x[0-9a-f]+$',  # Pure addresses
    r'^sub_[0-9a-f]+$', r'^loc_[0-9a-f]+$',  # Disassembler labels
    r'.*@plt$', r'.*\.plt$',  # PLT entries
    r'^__.*__$'  # System internal functions
]
```

## Technical Implementation

### Core Libraries and Dependencies
- **NetworkX**: Graph creation, analysis, and algorithms
- **Matplotlib**: Visualization generation (charts, heatmaps)
- **Pandas**: Data manipulation and CSV export
- **Python Standard Library**: Regular expressions, file I/O

### Key Components
1. **CallGraphNormalizer**: Handles format parsing and function name standardization
2. **MultiCallGraphComparator**: Main analysis engine and comparison logic
3. **Logger**: Dual output system (console + file logging)

### Error Handling and Robustness
- **Graceful Degradation**: Continues analysis if one tool fails (except critical tools)
- **File Validation**: Checks for file existence, readability, and content validity
- **Format Detection**: Automatic handling of different graph formats
- **Memory Management**: Efficient handling of large function sets

## Usage

### Basic Usage
```bash
# Place your call graph files in the graph/ directory:
# - graph/r2.dot (Radare2 output)
# - graph/ghidra.gf (Ghidra export)
# - graph/angr_fast.dot (Angr fast mode)
# - graph/angr_emul.dot (Angr emulation mode)

# Run the analysis
python3 run_analysis.py
```

### Input File Requirements
- **Radare2**: Export call graph as DOT format (`agC > r2.dot`)
- **Ghidra**: Export function graph in GF format
- **Angr**: Generate call graphs using CFG analysis in DOT format
- Files must be placed in the `graph/` directory with specific naming

### Command Line Options
The framework is designed for simplicity with minimal configuration required. All analysis parameters are automatically determined based on the input data characteristics.

## Output Generation

### Visualization Outputs
The framework generates multiple high-resolution PNG charts:
- **Function Discovery Comparison**: Bar charts showing total, high-level, and low-level function counts
- **Call Relationship Comparison**: Analysis of call relationship quantities across tools
- **Graph Density Comparison**: Visualization of graph connectivity metrics
- **Similarity Heatmap**: Color-coded Jaccard similarity matrix between all tool pairs

### Data Exports (CSV Format)
- **Statistics Summary**: Comprehensive metrics for each tool
- **Similarity Matrix**: Pairwise comparison coefficients
- **Function Comparison**: Detailed function-by-function analysis
- **Level Analysis**: High-level vs low-level function breakdown
- **Call Relationship Analysis**: Inter-function relationship mapping

### Logging and Reporting
- **Complete Analysis Log**: Detailed execution log with all intermediate results
- **Console Output**: Real-time progress and summary information
- **Error Reporting**: Comprehensive error handling with diagnostic information

## Generated Output Files

### Visualization Files (PNG)
- `result/function_discovery_comparison.png` - Function discovery analysis across tools
- `result/call_relationship_comparison.png` - Call relationship comparison charts
- `result/graph_density_comparison.png` - Graph density and connectivity metrics
- `result/similarity_heatmap.png` - Jaccard similarity matrix heatmap

### Data Export Files (CSV)
- `result/multi_callgraph_comparison_statistics.csv` - Comprehensive tool statistics
- `result/multi_callgraph_comparison_similarity.csv` - Pairwise similarity matrix
- `result/multi_callgraph_comparison_functions.csv` - Function-level comparison
- `result/function_level_analysis_statistics.csv` - High/low-level function statistics
- `result/function_level_analysis_high_level_functions.csv` - High-level function details
- `result/function_level_analysis_low_level_functions.csv` - Low-level function details
- `result/function_level_analysis_high_level_calls.csv` - High-level call relationships

### Log Files
- `analysis_log.txt` - Complete execution log with detailed analysis results

## Project Structure
```
analysis_comparison/
├── run_analysis.py              # Main execution script
├── multi_comparison.py          # Core analysis framework
├── graph/                       # Input directory for call graph files
│   ├── r2.dot                  # Radare2 call graph (DOT format)
│   ├── ghidra.gf               # Ghidra call graph (GF format)
│   ├── angr_fast.dot           # Angr fast mode (DOT format)
│   └── angr_emul.dot           # Angr emulation mode (DOT format)
├── result/                      # Output directory for all generated files
└── README.md                    # This documentation
```

## Analysis Capabilities

### Comparative Metrics
- **Function Discovery Efficiency**: Quantifies each tool's ability to identify functions
- **Call Graph Completeness**: Measures coverage of inter-function relationships
- **Analysis Precision**: Evaluates quality vs quantity trade-offs
- **Tool Complementarity**: Identifies unique contributions of each tool
- **Consistency Analysis**: Compares results between different analysis modes

### Statistical Analysis
- **Descriptive Statistics**: Mean, median, standard deviation of graph metrics
- **Distribution Analysis**: Function and call relationship distributions
- **Correlation Analysis**: Relationships between different metrics
- **Outlier Detection**: Identification of anomalous functions or relationships
- **Confidence Intervals**: Statistical significance of differences between tools

### Scalability Considerations
- **Large Binary Support**: Efficient handling of binaries with thousands of functions
- **Memory Optimization**: Streaming analysis for memory-constrained environments
- **Performance Monitoring**: Execution time tracking and optimization
- **Parallel Processing**: Support for concurrent tool execution
- **Incremental Analysis**: Ability to update results with new tool outputs

## Extensibility

### Adding New Analysis Tools
The framework is designed for easy extension to support additional binary analysis tools:
1. Implement format parser in `CallGraphNormalizer`
2. Add tool configuration to `tools` dictionary
3. Update error handling for tool-specific failures
4. Extend visualization to accommodate additional tools

### Custom Analysis Metrics
Users can extend the analysis by adding custom metrics:
- Implement new metric calculations in `_calculate_graph_metrics`
- Add visualization support in chart generation functions
- Update CSV export formats to include new metrics
- Modify report generation for additional insights

## Limitations and Considerations

### Known Limitations
- **Format Dependencies**: Requires specific output formats from each tool
- **Function Name Ambiguity**: Some normalization may merge distinct functions
- **Tool Version Sensitivity**: Results may vary with different tool versions
- **Binary Architecture**: Optimized for x86/x64 architectures
- **Analysis Depth**: Focus on call graphs, not control flow within functions

### Best Practices
- **Consistent Tool Versions**: Use stable, documented versions of analysis tools
- **Validation**: Cross-reference critical findings with manual analysis
- **Documentation**: Maintain records of tool configurations and parameters
- **Iterative Analysis**: Re-run analysis with different tool settings for comprehensive results
- **Quality Assurance**: Verify input file integrity before analysis